{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea361880-fbc4-4509-8c3c-34810e02b6e4",
   "metadata": {},
   "source": [
    "Dado que estamos trabajando en un problema de regresión, necesitamos definir una variable objetivo numérica. Supongamos que elegimos Work_Experience como variable objetivo, para predecir la experiencia laboral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db836c8-795c-46d6-9402-fb6fc046d4b3",
   "metadata": {},
   "source": [
    "### Pasos para el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64250021-560b-48f0-aeb1-96dd08b0be16",
   "metadata": {},
   "source": [
    "1. Preprocesamiento:\n",
    "Eliminar columnas irrelevantes: La columna ID no es útil para el modelo.\n",
    "\n",
    "Codificación de variables categóricas:\n",
    "\n",
    "Gender, Ever_Married, Graduated, Profession, Spending_Score, Var_1 son categóricas y deben codificarse (usar OneHotEncoder).\n",
    "\n",
    "2. Escalado de variables numéricas:\n",
    "\n",
    "Age, Work_Experience, Family_Size deben escalarse (usar StandardScaler o MinMaxScaler)\n",
    "Modelo de regresión:\n",
    "\n",
    "Usar GradientBoostingRegressor (de sklearn) o XGBRegressor (de XGBoost).\n",
    "\n",
    "3. Optimización con Grid Search:\n",
    "\n",
    "Definir un espacio de búsqueda para los hiperparámetros del modelo.\n",
    "\n",
    "4. Evaluación:\n",
    "\n",
    "Predecir en el conjunto de prueba (test.csv).\n",
    "\n",
    "Calcular métricas como MSE y R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1acf3ec-0fc2-420e-84e0-17447c62b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 3, 'regressor__min_samples_split': 5, 'regressor__n_estimators': 100}\n",
      "MSE en test: 9.450497113677942\n",
      "R² en test: 0.15304284162155302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar datos de entrenamiento y prueba\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "# Eliminar filas donde 'Work_Experience' es NaN\n",
    "train_data = train_data.dropna(subset=['Work_Experience'])\n",
    "test_data = test_data.dropna(subset=['Work_Experience'])\n",
    "\n",
    "# Definir características (X) y objetivo (y)\n",
    "# Supongamos que queremos predecir 'Work_Experience'\n",
    "X_train = train_data.drop(columns=['ID', 'Work_Experience', 'Segmentation'])  # Eliminar columnas irrelevantes\n",
    "y_train = train_data['Work_Experience']\n",
    "\n",
    "X_test = test_data.drop(columns=['ID', 'Work_Experience', 'Segmentation'])  # Eliminar columnas irrelevantes\n",
    "y_test = test_data['Work_Experience']\n",
    "\n",
    "# Definir columnas numéricas y categóricas\n",
    "numeric_features = ['Age', 'Family_Size']\n",
    "categorical_features = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "\n",
    "# Preprocesamiento con imputación\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Imputar valores faltantes con la mediana\n",
    "    ('scaler', StandardScaler())  # Escalar características numéricas\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar valores faltantes con la moda\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Codificar características categóricas\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline con preprocesamiento y modelo\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Definir espacio de búsqueda para Grid Search\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],  # Número de árboles\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
    "    'regressor__max_depth': [3, 5, 10],  # Profundidad máxima de los árboles\n",
    "    'regressor__min_samples_split': [2, 5, 10]  # Mínimo de muestras para dividir un nodo\n",
    "}\n",
    "\n",
    "# Configurar Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo con Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"MSE en test:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R² en test:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5664bb-d940-47fd-9855-a5ac68bcf30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
